{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The unreasonable effectiveness of Character-level Language Models\n",
    "## (and why RNNs are still cool)\n",
    "\n",
    "### [Yoav Goldberg](http://www.cs.biu.ac.il/~yogo)\n",
    "\n",
    "RNNs, LSTMs and Deep Learning are all the rage, and a recent [blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) by Andrej Karpathy is doing a great job explaining what these models are and how to train them.\n",
    "It also provides some very impressive results of what they are capable of.  This is a great post, and if you are interested in natural language, machine learning or neural networks you should definitely read it. \n",
    "\n",
    "Go read it now, then come back here. \n",
    "\n",
    "You're back? good. Impressive stuff, huh? How could the network learn to immitate the input like that?\n",
    "Indeed. I was quite impressed as well.\n",
    "\n",
    "However, it feels to me that most readers of the post are impressed by the wrong reasons.\n",
    "This is because they are not familiar with **unsmoothed maximum-liklihood character level language models** and their unreasonable effectiveness at generating rather convincing natural language outputs.\n",
    "\n",
    "In what follows I will briefly describe these character-level maximum-likelihood langauge models, which are much less magical than RNNs and LSTMs, and show that they too can produce a rather convincing Shakespearean prose. I will also show about 30 lines of python code that take care of both training the model and generating the output. Compared to this baseline, the RNNs may seem somehwat less impressive. So why was I impressed? I will explain this too, below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsmoothed Maximum Likelihood Character Level Language Model \n",
    "\n",
    "The name is quite long, but the idea is very simple.  We want a model whose job is to guess the next character based on the previous $n$ letters. For example, having seen `ello`, the next characer is likely to be either a commma or space (if we assume is is the end of the word \"hello\"), or the letter `w` if we believe we are in the middle of the word \"mellow\". Humans are quite good at this, but of course seeing a larger history makes things easier (if we were to see 5 letters instead of 4, the choice between space and `w` would have been much easier).\n",
    "\n",
    "We will call $n$, the number of letters we need to guess based on, the _order_ of the language model.\n",
    "\n",
    "RNNs and LSTMs can potentially learn infinite-order language model (they guess the next character based on a \"state\" which supposedly encode all the previous history). We here will restrict ourselves to a fixed-order language model.\n",
    "\n",
    "So, we are seeing $n$ letters, and need to guess the $n+1$th one. We are also given a large-ish amount of text (say, all of Shakespear works) that we can use. How would we go about solving this task?\n",
    "\n",
    "Mathematiacally, we would like to learn a function $P(c | h)$. Here, $c$ is a character, $h$ is a $n$-letters history, and $P(c|h)$ stands for how likely is it to see $c$ after we've seen $h$.\n",
    "\n",
    "Perhaps the simplest approach would be to just count and divide (a.k.a **maximum likelihood estimates**). We will count the number of times each letter $c'$ appeared after $h$, and divide by the total numbers of letters appearing after $h$. The **unsmoothed** part means that if we did not see a given letter following $h$, we will just give it a probability of zero.\n",
    "\n",
    "And that's all there is to it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Code\n",
    "Here is the code for training the model. `fname` is a file to read the characters from. `order` is the history size to consult. Note that we pad the data with leading `~` so that we also learn how to start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import *\n",
    "\n",
    "def train_char_lm(fname, order=4):\n",
    "    data = file(fname).read()\n",
    "    lm = defaultdict(Counter)\n",
    "    pad = \"~\" * order\n",
    "    data = pad + data\n",
    "    for i in xrange(len(data)-order):\n",
    "        history, char = data[i:i+order], data[i+order]\n",
    "        lm[history][char]+=1\n",
    "    def normalize(counter):\n",
    "        s = float(sum(counter.values()))\n",
    "        return [(c,cnt/s) for c,cnt in counter.iteritems()]\n",
    "    outlm = {hist:normalize(chars) for hist, chars in lm.iteritems()}\n",
    "    return outlm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train it on Andrej's Shakespears's text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-09-29 11:41:11--  http://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\n",
      "Resolving cs.stanford.edu... 171.64.64.64\n",
      "Connecting to cs.stanford.edu|171.64.64.64|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4573338 (4.4M) [text/plain]\n",
      "Saving to: ‘shakespeare_input.txt’\n",
      "\n",
      "shakespeare_input.t 100%[===================>]   4.36M  8.61MB/s    in 0.5s    \n",
      "\n",
      "2017-09-29 11:41:12 (8.61 MB/s) - ‘shakespeare_input.txt’ saved [4573338/4573338]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. Now let's do some queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('!', 0.0068143100511073255),\n",
       " (' ', 0.013628620102214651),\n",
       " (\"'\", 0.017035775127768313),\n",
       " (',', 0.027257240204429302),\n",
       " ('.', 0.0068143100511073255),\n",
       " ('r', 0.059625212947189095),\n",
       " ('u', 0.03747870528109029),\n",
       " ('w', 0.817717206132879),\n",
       " ('n', 0.0017035775127768314),\n",
       " (':', 0.005110732538330494),\n",
       " ('?', 0.0068143100511073255)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['ello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t', 1.0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['Firs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'\", 0.0008025682182985554),\n",
       " ('A', 0.0056179775280898875),\n",
       " ('C', 0.09550561797752809),\n",
       " ('B', 0.009630818619582664),\n",
       " ('E', 0.0016051364365971107),\n",
       " ('D', 0.0032102728731942215),\n",
       " ('G', 0.0898876404494382),\n",
       " ('F', 0.012038523274478331),\n",
       " ('I', 0.009630818619582664),\n",
       " ('H', 0.0040128410914927765),\n",
       " ('K', 0.008025682182985553),\n",
       " ('M', 0.0593900481540931),\n",
       " ('L', 0.10674157303370786),\n",
       " ('O', 0.018459069020866775),\n",
       " ('N', 0.0008025682182985554),\n",
       " ('P', 0.014446227929373997),\n",
       " ('S', 0.16292134831460675),\n",
       " ('R', 0.0008025682182985554),\n",
       " ('T', 0.0032102728731942215),\n",
       " ('W', 0.033707865168539325),\n",
       " ('a', 0.02247191011235955),\n",
       " ('c', 0.012841091492776886),\n",
       " ('b', 0.024879614767255216),\n",
       " ('e', 0.0032102728731942215),\n",
       " ('d', 0.015248796147672551),\n",
       " ('g', 0.011235955056179775),\n",
       " ('f', 0.011235955056179775),\n",
       " ('i', 0.016853932584269662),\n",
       " ('h', 0.019261637239165328),\n",
       " ('k', 0.0040128410914927765),\n",
       " ('m', 0.02247191011235955),\n",
       " ('l', 0.01043338683788122),\n",
       " ('o', 0.030497592295345103),\n",
       " ('n', 0.020064205457463884),\n",
       " ('q', 0.0016051364365971107),\n",
       " ('p', 0.00882825040128411),\n",
       " ('s', 0.03290529695024077),\n",
       " ('r', 0.0072231139646869984),\n",
       " ('u', 0.0016051364365971107),\n",
       " ('t', 0.05377207062600321),\n",
       " ('w', 0.024077046548956663),\n",
       " ('v', 0.002407704654895666),\n",
       " ('y', 0.002407704654895666)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['rst ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `ello` is followed by either space, punctuation or `w` (or `r`, `u`, `n`), `Firs` is pretty much deterministic, and the word following `ist ` can start with pretty much every letter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating from the model\n",
    "Generating is also very simple. To generate a letter, we will take the history, look at the last $order$ characteters, and then sample a random letter based on the corresponding distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def generate_letter(lm, history, order):\n",
    "        history = history[-order:]\n",
    "        dist = lm[history]\n",
    "        x = random()\n",
    "        for c,v in dist:\n",
    "            x = x - v\n",
    "            if x <= 0: return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a passage of $k$ characters, we just seed it with the initial history and run letter generation in a loop, updating the history at each turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text(lm, order, nletters=1000):\n",
    "    history = \"~\" * order\n",
    "    out = []\n",
    "    for i in xrange(nletters):\n",
    "        c = generate_letter(lm, history, order)\n",
    "        history = history[-order:] + c\n",
    "        out.append(c)\n",
    "    return \"\".join(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Shakespeare from different order models\n",
    "\n",
    "Let's try to generate text based on different language-model orders. Let's start with something silly:\n",
    "\n",
    "### order 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fir, th\n",
      "Theessing to he at wit,\n",
      "Norm Des then oth mord, beld thromet hin weake riefour any for ferty?\n",
      "And my meatermse he to makes mand: haterse at you, be in he card natery, bou fand on pure's re ain goot eventle enot chatinight wouslad hime Baptill in-men weeple?\n",
      "\n",
      "Sirtakess't this sommels but hat sto eiss sh, wharks:\n",
      "We I dearcesinaked be face samin brood.\n",
      "Sece soughtly,\n",
      "Is briewel st you--\n",
      "\n",
      "KING Romears you be! thir?\n",
      "I haroke fody the ow withers th thend her, deect apeace.\n",
      "Ay, beggaved oake whicus,\n",
      "Thave hold, I dre virs,\n",
      "fore:\n",
      "Am 'hoselcomeral o's us ded hin wixt Why,\n",
      "Salbospee: dou that wit.\n",
      "\n",
      "And liveread hom is of twit costen's man, welcouts, hathas aninke minkin Edware the not ade, thou hosed\n",
      "pep is dearr's falt: ink ger bur me\n",
      "It And olsen em on.\n",
      "\n",
      "Loolts, to:\n",
      "I man be of to\n",
      "beind ther sausir. Whal a Giver, fand cand I weet is med hised gengue it pored ung: 't:\n",
      "Why, courefe,\n",
      "To els, the fall we hath thour he andied up man Sper isty'refur Surs the at have ford, I welorry stinand \n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=2)\n",
    "print generate_text(lm, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so great.. but what if we increase the order to 4?\n",
    "\n",
    "### order 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First need on't like.\n",
      "\n",
      "KING HENRY IV:\n",
      "Say, go to live the him, we'll give me audaciously\n",
      "to be terready.\n",
      "Call have soft this made to see to man\n",
      "And then? how,\n",
      "From that rest are you hath hast I will commanderstant your gentleman,\n",
      "Thou would not, Sir John, you are at he powers\n",
      "to take thee claim on to your climb should of valiancasest it is the friend your pring Lewishes those that their with thus drain,\n",
      "And, nor the play tongue;\n",
      "For, but to't: 'tis gold:\n",
      "We hast more\n",
      "Harm my lord:\n",
      "The secretion joy is undo dish chough yoke lord?\n",
      "\n",
      "PEMBROKE:\n",
      "So am to used the cannot a king's that I am bounding bloody, groaning face?\n",
      "\n",
      "STEPHANO:\n",
      "Caesar, set.\n",
      "\n",
      "CANTERBURY:\n",
      "Hark! what herefores trius.\n",
      "\n",
      "DUCHESS QUICKLY:\n",
      "Go, call nothing disdain we had regard\n",
      "Young, from of knight I beauty take your petite,\n",
      "And, and for my most villant, to that my namest as you calm,\n",
      "Unlike a shall yea, two?\n",
      "\n",
      "SUFFOLK:\n",
      "Because and swore vow'd at the will\n",
      "whither\n",
      "oppose\n",
      "me this by not Gaoler:\n",
      "My king\n",
      "To bring, Sir John, we will n\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)\n",
    "print generate_text(lm, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Gentleman:\n",
      "If therefore, were were 'tis; and among terms in fault?\n",
      "\n",
      "BARDOLPH:\n",
      "Brave.\n",
      "\n",
      "Constand,\n",
      "as ther's; we matten haster:\n",
      "My lord! On Thy browns not victor?\n",
      "\n",
      "Fool:\n",
      "I pray\n",
      "the me his day?\n",
      "\n",
      "CARDINAL CAMPEIUS:\n",
      "Come entreach done to Claudio's,\n",
      "To friends,\n",
      "Would we, than with to Timony.\n",
      "\n",
      "DON ADRIANA:\n",
      "Why, which thee!\n",
      "\n",
      "MARK ANTONY:\n",
      "'Twere\n",
      "And is no morrows,\n",
      "And the devil an you refuge been the who\n",
      "Shrunk!\n",
      "\n",
      "First-born,\n",
      "As go youth thee are you;\n",
      "Your patience\n",
      "designieur draw, I to your any poor and I have to statesby, made not you are thy done:\n",
      "Impromio?\n",
      "The plots heard.\n",
      "\n",
      "BENVOLIO:\n",
      "Believe; gives,\n",
      "Any treason.\n",
      "The needs much all cock; and am apprehends.\n",
      "\n",
      "LAFEU:\n",
      "Your lusty.\n",
      "\n",
      "DON ADRIANA:\n",
      "Nay, I'll conscience he shall find wrong answer\n",
      "With the time comes yielders.\n",
      "\n",
      "TAMORA:\n",
      "My lord, and on your requite men!\n",
      "\n",
      "DEMETRIUS:\n",
      "Well man like hail, when die ere before is not a bounter,\n",
      "And what can very for three day.\n",
      "\n",
      "GADSHILLE:\n",
      "At you, hearteen must stance! coward.\n",
      "\n",
      "TIMON:\n",
      "I tell breatening: 't\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)\n",
    "print generate_text(lm, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is already quite reasonable, and reads like English. Just 4 letters history! What if we increase it to 7?\n",
    "\n",
    "### order 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "O royal head in two daughters,\n",
      "You and me;\n",
      "Which thou so look'd not and let 'em win the end.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "My lord, he fearful?\n",
      "\n",
      "Messenger:\n",
      "Gracious meet withal?\n",
      "\n",
      "HORTENSIO:\n",
      "I have been his great men;\n",
      "For the power he comes your pleasure in the achieved as his: it was,'--\n",
      "the juvenal? why then their brethren.\n",
      "\n",
      "QUINTUS:\n",
      "Right, you do me, if these wall;\n",
      "And our tardy soldiers are wound that enwraps me heart of this is a devil in an ass and our court. Let us revenge his cur the thunders by, I could not Marcius,\n",
      "I have almost a mile, and doughy youth and speed, we will enfranchise you: but a limb?\n",
      "\n",
      "FERDINAND:\n",
      "Thy oath remorse: swear the head of your face to think he is gone,\n",
      "Having four.\n",
      "Now I have sent to make\n",
      "this in my life\n",
      "Became the parties, and blind, thou ever blush and blood, spirit of his good your swords.\n",
      "\n",
      "SOMERSET:\n",
      "No such matter: what thought:\n",
      "The higher by pure love me, sir, no more should\n",
      "comedy.\n",
      "\n",
      "MALVOLIO:\n",
      "Sir Valentine,\n",
      "Now mingled than they have dancing a\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=7)\n",
    "print generate_text(lm, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "That can I witness with him, thief!\n",
      "\n",
      "IAGO:\n",
      "Yet be contented,\n",
      "Forswear Bianca and her lord is come.\n",
      "\n",
      "Nurse:\n",
      "By my troth,\n",
      "welcome too.\n",
      "How dearly they do't! 'Tis her breath.'\n",
      "\n",
      "LAUNCE:\n",
      "Ay, that's the\n",
      "scene that I was sent thither, and he is one of these drones, that robb'd these men have died when Claudio lie,\n",
      "Who loved his father,\n",
      "Henry the Seventh succeeded in his rages, and his daughter were legitimate: fine word,--legitimate: fine word,--legitimate construction.\n",
      "\n",
      "TAMORA:\n",
      "O cruel, irreligious truth and upright,\n",
      "Like softest music to her ear.\n",
      "\n",
      "THURIO:\n",
      "Nay then, two treys, and if your garments sit upon me;\n",
      "Sometime she driveth o'er a soldier, that shall Clarence closely mew'd her up,\n",
      "Because I love him welcome,\n",
      "While I use further spoken,\n",
      "That you are.\n",
      "\n",
      "POSTHUMUS LEONATUS:\n",
      "Agreed.\n",
      "\n",
      "MARCUS ANDRONICUS:\n",
      "I give it you, my lord well, that I have seen our wishes had a womb.\n",
      "And fertile: let a\n",
      "beast be lord of such another to Page's wife, with my lady? mistress,\n",
      "That make ingrate\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=10)\n",
    "print generate_text(lm, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This works pretty well\n",
    "\n",
    "With an order of 4, we already get quite reasonable results. Increasing the order to 7 (~word and a half of history) or 10 (~two short words of history) already gets us quite passable Shakepearan text. I'd say it is on par with the examples in Andrej's post. And how simple and un-mystical the model is!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So why am I impressed with the RNNs after all?\n",
    "\n",
    "Generating English a character at a time -- not so impressive in my view. The RNN needs to learn the previous $n$ letters, for a rather small $n$, and that's it. \n",
    "\n",
    "However, the code-generation example is very impressive. Why? because of the context awareness. Note that in all of the posted examples, the code is well indented, the braces and brackets are correctly nested, and even the comments start and end correctly. This is not something that can be achieved by simply looking at the previous $n$ letters. \n",
    "\n",
    "If the examples are not cherry-picked, and the output is generally that nice, then the LSTM did learn something not trivial at all.\n",
    "\n",
    "Just for the fun of it, let's see what our simple language model does with the linux-kernel code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-09-29 11:42:10--  http://cs.stanford.edu/people/karpathy/char-rnn/linux_input.txt\n",
      "Resolving cs.stanford.edu... 171.64.64.64\n",
      "Connecting to cs.stanford.edu|171.64.64.64|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6206996 (5.9M) [text/plain]\n",
      "Saving to: ‘linux_input.txt’\n",
      "\n",
      "linux_input.txt     100%[===================>]   5.92M  8.97MB/s    in 0.7s    \n",
      "\n",
      "2017-09-29 11:42:11 (8.97 MB/s) - ‘linux_input.txt’ saved [6206996/6206996]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://cs.stanford.edu/people/karpathy/char-rnn/linux_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~\n",
      " *     waiters.  For requeue_pi code can enforce the read-side critical section,\n",
      " * as long as this is needed for procs, tasks) for each trigger associated\n",
      " * to not have a bug somewhere outside mems_allowed mask from\n",
      " * then on but never vice versa.  Handle both possibility to update the clocksource_delta(csnow, cs->cs_last = csnow;\n",
      "\t\t\tcontinue;\n",
      "\t\t/*\n",
      "\t\t * Print torture_rwlock_read_data *rd)\n",
      "{\n",
      "\t/* used to incremented once, even if this means that the timekeeping_apply_adjustment, sem) &\n",
      "\t\t\t\t\t\tRWSEM_ACTIVE_READ_BIAS;\n",
      "\tstruct irq_desc *desc, unsigned long mem_len,\n",
      "\t\t\t\t\tstruct rt_mutex *lock, struct task_struct *task = (struct syscall_metadata *)call->data;\n",
      "\tint busiest_capacity;\n",
      "\tunsigned long flags;\n",
      "\tint res, ret;\n",
      "\n",
      "\tif (page_to_pfn(page));\n",
      "}\n",
      "\n",
      "static int\n",
      "func_set_flag(struct file *filp, int on)\n",
      "{\n",
      "\tstruct lock_class(struct tracer_opt trace_options_init_dentry(tr);\n",
      "\tif (ret < 0)\n",
      "\t\treturn;\n",
      "\t\t}\n",
      "\t\tif (opts->release_agent);\n",
      "\tif (likely(list_empty(&trace_bprint_event_file *file,\n",
      "\t\t\t  char *bu\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=10)\n",
    "print generate_text(lm, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " *     wait->flags &= ~WQ_FLAG_EXCLUSIVE;\n",
      "\tspin_lock_irq(&rq->lock);\n",
      "\n",
      "\treturn ret;\n",
      "}\n",
      "\n",
      "static int irq_node_proc_show(struct seq_file *s, void *unused)\n",
      "{\n",
      "\tif (ftrace_dump_on_oops);\n",
      "\treturn NOTIFY_DONE;\n",
      "\t}\n",
      "\treturn NOTIFY_OK;\n",
      "\tmutex_lock(&show_mutex);\n",
      "\tswitch (val) {\n",
      "\tcase 0:\n",
      "\t\t/*\n",
      "\t\t * When soft_disable is not set but the SOFT_MODE flag */\n",
      "\t\t__ftrace_event_enable_disable_cmds(void)\n",
      "{\n",
      "\tint i, cpu;\n",
      "\n",
      "\tdepth = curr->lockdep_depth; i++) {\n",
      "\t\thlock = curr->held_locks + i;\n",
      "\t\t/*\n",
      "\t\t * We dont care about collisions. Nodes with\n",
      "\t\t * the same object file are loaded.\n",
      "\t\t * The initial one takes precedence.\n",
      "\t\t */\n",
      "\t\tif (!chain_head && ret != 2)\n",
      "\t\t\tif (!check_prev_add(curr, hlock, next,\n",
      "\t\t\t\t\t\tdistance, trylock_loop))\n",
      "\t\t\t\treturn 0;\n",
      "\t\tchain_head = 1;\n",
      "\t}\n",
      "\tchain_key = iterate_chain_key(key1, key2) \\\n",
      "\t(((key1) << MAX_LOCKDEP_CHAIN_HLOCKS);\n",
      "#endif\n",
      "\n",
      "#ifdef CONFIG_TRACE_IRQFLAGS) && defined(CONFIG_CFS_BANDWIDTH\n",
      "static DEFINE_PER_CPU(struct rcu_dynticks *rdtp = this_cpu_ptr(lg->lock, i);\n",
      "\t\tarch_spin_unlock(&cfs_b->\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=15)\n",
    "print generate_text(lm, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/proc.c\n",
      " *\n",
      " * Copyright 2003-2004 Red Hat, Inc.\n",
      " * Copyright (C) 2012 Rafael J. Wysocki <rjw@sisk.pl>\n",
      " */\n",
      "\n",
      "#include <linux/personality.h>\n",
      "#include <linux/init_task.h>\n",
      "#include <linux/debug_locks.h>\n",
      "\n",
      "#include \"mutex-debug.h\"\n",
      "\n",
      "/*\n",
      " * Must be called with pm_mutex held.  If it is successful, control\n",
      " * reappears in the restored target kernel.\n",
      " */\n",
      "static int resume_target_kernel(bool platform_mode)\n",
      "{\n",
      "\tint error;\n",
      "\n",
      "\terror = memory_bm_find_bit(bm, pfn, &addr, &bit);\n",
      "\tif (!error)\n",
      "\t\tset_bit(bit, addr);\n",
      "\n",
      "\treturn error;\n",
      "}\n",
      "\n",
      "static int kill_as_cred_perm(const struct cred *new, const struct cred *cred = current_cred(), *tcred;\n",
      "\n",
      "\tif (current == task)\n",
      "\t\treturn 0;\n",
      "\n",
      "\ttcred = __task_cred(tsk);\n",
      "\t\tif (!uid_eq(cred->uid, make_kuid(ns, 0)) ||\n",
      "\t\t    !gid_eq(cred->gid, make_kgid(ns, 0)))\n",
      "\t\t\tgoto out;\n",
      "\t}\n",
      "\n",
      "\trec->counter++;\n",
      " out:\n",
      "\tlocal_irq_restore(flags);\n",
      "\t\t\treturn;\n",
      "\t\t}\n",
      "\t\tmask = rnp->grpmask;\n",
      "\t\tif (rnp->parent == NULL) {\n",
      "\t\t\traw_spin_unlock(&rnp_up->lock); /* irqs still off */\n",
      "\t}\n",
      "\traw_spin_unl\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=20)\n",
    "print generate_text(lm, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/pm.c\n",
      " *\n",
      " * Copyright (C) 2012 Bojan Smojver <bojan@rexursive.com>\n",
      " *\n",
      " * This file is subject to the terms and conditions of the GNU General Public License\n",
      "* along with this program; if not, write to the Free Software\n",
      "    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307, USA.\n",
      " *\n",
      " * Copyright (C) 2012 Rafael J. Wysocki <rjw@sisk.pl>\n",
      " */\n",
      "\n",
      "#include <linux/irq.h>\n",
      "#include <linux/smp.h>\n",
      "#include <linux/delay.h>\n",
      "#include <linux/slab.h>\n",
      "#include <linux/kernel.h>\n",
      "#include <linux/workqueue.h>\n",
      "#include <linux/futex.h>\n",
      "#include <linux/rcupdate.h>\n",
      "#include <linux/err.h>\n",
      "#include <linux/console.h>\n",
      "#include <linux/seq_file.h>\n",
      "#include <linux/kgdb.h>\n",
      "#include <linux/syscalls.h>\n",
      "#include <linux/ptrace.h>\n",
      "#include <linux/pid_namespace.h>\n",
      "#include <net/genetlink.h>\n",
      "#include <linux/stat.h>\n",
      "#include <linux/module.h>\n",
      "\n",
      "#define CREATE_TRACE_POINTS\n",
      "#include \"trace_events_filter_test\n",
      "\n",
      "/* This part must be outside protection */\n",
      "#include <trace/define_trace.h>\n",
      "/* audit --\n"
     ]
    }
   ],
   "source": [
    "print generate_text(lm, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * linux/kernel/irq/spurious.c\n",
      " *\n",
      " * Copyright (C) Jay Lan,\t<jlan@sgi.com>\n",
      " *\n",
      " *\n",
      " * This program is distributed in the hope that it will be useful,\n",
      " * but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      " * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n",
      " * General Public License for more details.\n",
      " *\n",
      " * You should have received a copy of the GNU General Public License\n",
      " * along with this program; if not, you can access it online at\n",
      " * http://www.gnu.org/licenses/>.\n",
      " */\n",
      "\n",
      "#define pr_fmt(fmt) \"Kprobe smoke test: \" fmt\n",
      "\n",
      "#include <linux/ctype.h>\n",
      "#include <linux/freezer.h>\n",
      "\n",
      "#include <asm/setup.h>\n",
      "\n",
      "#include \"trace.h\"\n",
      "\n",
      "/* Our two options */\n",
      "enum {\n",
      "\tTRACE_NOP_OPT_ACCEPT) },\n",
      "\t/* Option that will be accepted by set_flag callback */\n",
      "\t{ TRACER_OPT(test_nop_accept, TRACE_NOP_OPT_ACCEPT = 0x1,\n",
      "\tTRACE_NOP_OPT_REFUSE) },\n",
      "\t{ } /* Always set a last empty entry */\n",
      "};\n",
      "\n",
      "static struct trace_kprobe, tp.args) +\t\\\n",
      "\t(sizeof(struct probe_arg) * (n)))\n",
      "\n",
      "\n",
      "static nokprobe_inline unsigned long\n",
      "memcpy_skip(void *dst, const void *src, unsigned long len)\n",
      "{\n",
      "\tdo {\n",
      "\t\tunsigned long next;\n",
      "\n",
      "\t\tif (p->rt.watchdog_stamp = jiffies;\n",
      "\t\t}\n",
      "\n",
      "\t\tnext = DIV_ROUND_UP(min(soft, hard), USEC_PER_SEC/HZ);\n",
      "\t\tif (p->rt.timeout > next)\n",
      "\t\t\tp->cputime_expires.sched_exp = p->se.sum_exec_runtime;\n",
      "#endif\n",
      "\n",
      "\trq = task_rq_lock(tsk, &flags);\n",
      "\n",
      "\trunning = task_current(rq, p);\n",
      "\tif (queued)\n",
      "\t\tdequeue_task(rq, p, 0);\n",
      "\t__setscheduler(rq, p, &attr);\n",
      "\tif (queued) {\n",
      "\t\t/*\n",
      "\t\t * We enqueue to tail when the priority of a task\n",
      " * - the caller must hold the base lock.\n",
      " *\n",
      " * Returns 0 on successful registration, -errno on failure.\n",
      " */\n",
      "static int __rcu_pending(struct seq_file *m, void *v)\n",
      "{\n",
      "\tunion trace_enum_map_item *v;\n",
      "\tloff_t l = 0;\n",
      "\n",
      "\tpreempt_disable();\n",
      "\tshow_regs(regs);\n",
      "\tkdb_trap_printk--;\n",
      "\tkdb_printf(\"\\n\");\n",
      "#else\n",
      "\tif (len)\n",
      "\t\treturn len;\n",
      "\n",
      "\tfor (i = 0; i < ftrace_graph_count;\n",
      "extern unsigned long __start_branch_profile[];\n",
      "extern unsigned int nr_hardirq_chains;\n",
      "extern unsigned int nr_softirq_chains;\n",
      "extern unsigned int max_bfs_queue_depth;\n",
      "\n",
      "#ifdef CONFIG_DEBUG_PREEMPT) || \\\n",
      "\t\t\t\tdefined(CONFIG_PREEMPT_TRACER */\n",
      "\n",
      "#ifdef CONFIG_BRANCH_TRACER\n",
      "int\n",
      "trace_selftest_startup_function(struct trace_array *tr, int graph, int set)\n",
      "{\n",
      "\tint ret;\n",
      "\n",
      "\tmutex_lock(&cgrp->pidlist_mutex);\n",
      "\n",
      "\t/*\n",
      "\t * If the context we're installing events in is not the\n",
      "\t * active task_ctx, flip them.\n",
      "\t */\n",
      "\tif (ctx->task && cpuctx->task_ctx == ctx) {\n",
      "\t\tctx->is_active = 0;\n",
      "\t\tcpuctx->task_ctx = NULL;\n",
      "\t\traw_spin_unlock(&cputimer->lock);\n",
      "}\n",
      "\n",
      "/**\n",
      " * account_group_exec_runtime(curr, delta_exec);\n",
      "\n",
      "\tsched_rt_avg_update(rq, delta_exec);\n",
      "\n",
      "\tif (!rt_bandwidth_enabled())\n",
      "\t\treturn;\n",
      "\n",
      "\t/* Adjust nesting, check for fully idle. */\n",
      "\tif (irq) {\n",
      "\t\trdtp->dynticks_nesting = 0;\n",
      "\t\trcu_eqs_enter_common(oldval, true);\n",
      "\trcu_sysidle_enter(1);\n",
      "\tlocal_irq_restore(flags);\n",
      "}\n",
      "\n",
      "static void cpu_cgroup_fork(struct task_struct *tsk)\n",
      "{\n",
      "\tstruct mm_struct *mm)\n",
      "{\n",
      "\tstruct vm_area_struct *vma;\n",
      "\tunsigned long started;\n",
      "\tunsigned long count, flags;\n",
      "\tint ret;\n",
      "\n",
      "\tif (!desc->count)\n",
      "\t\treturn 0;\n",
      "\n",
      "#ifdef CONFIG_PERF_EVENTS\n",
      "\tif (call->perf_refcount)\n",
      "\t\treturn -EBUSY;\n",
      "#endif\n",
      "\n",
      "\tif (!info->spare)\n",
      "\t\tinfo->spare = ring_buffer_alloc(size, rb_flags);\n",
      "\tif (!buf->buffer)\n",
      "\t\treturn -ENOMEM;\n",
      "\n",
      "\text->start = swap_offset;\n",
      "\text->end = swap_offset;\n",
      "\trb_link_node(&ext->node, parent, new);\n",
      "\trb_insert_color(&se->run_node, &cfs_rq->tasks_timeline);\n",
      "\n",
      "\tif (!last)\n",
      "\t\treturn NULL;\n",
      "\n",
      "\treturn seq_list_next(p, &modules, pos);\n",
      "}\n",
      "\n",
      "static void *t_hash_start(struct seq_file *m, void *v, loff_t *pos)\n",
      "{\n",
      "\treturn seq_list_next(v, &ftrace_pids, pos);\n",
      "}\n",
      "\n",
      "static void lock_torture_cleanup(void)\n",
      "{\n",
      "\tint i;\n",
      "\n",
      "\ttorture_stop_kthread(lock_torture_writer,\n",
      "\t\t\t\t\t     writer_tasks[i]);\n",
      "\t\tkfree(writer_tasks);\n",
      "\t\twriter_tasks = NULL;\n",
      "\t}\n",
      "\n",
      "\ttorture_stop_kthread(rcu_torture_boost, NULL,\n",
      "\t\t\t\t\t\t  cpu_to_node(cpu),\n",
      "\t\t\t\t\t\t  GFP_KERNEL, 0);\n",
      "\t\tif (p == NULL) {\n",
      "\t\t\terr_cpu = cpu;\n",
      "\t\t\tgoto err;\n",
      "\t\t}\n",
      "\t}\n",
      "\tmutex_unlock(&kprobe_mutex);\n",
      "\n",
      "\t/* Wait for unoptimizing completion */\n",
      "\twait_for_kprobe_optimizer();\n",
      "}\n",
      "\n",
      "/* Wait for completing optimization and unoptimization */\n",
      "static void wait_for_kprobe_optimizer();\n",
      "\tprintk(KERN_INFO \"ftrace bootup tracer '%s' not registered.\\n\",\n",
      "\t       default_bootup_tracer = bootup_tracer_buf;\n",
      "\t/* We are using ftrace early, expand it */\n",
      "\tring_buffer_expanded = true;\n",
      "\treturn 1;\n",
      "}\n",
      "__setup(\"relax_domain_level=\", setup_relax_domain_level(char *str)\n",
      "{\n",
      "\tif (kstrtoint(str, 0, &default_relax_domain_level < c->relax_domain_level < 0)\n",
      "\t\t\treturn;\n",
      "\t\telse\n",
      "\t\t\trequest = default_relax_domain_level = val;\n",
      "\t\tif (!cpumask_empty(cs->cpus_allowed) || nodes_empty(cs->mems_allowed))\n",
      "\t\tupdate_tasks_nodemask(struct cpuset *cs)\n",
      "{\n",
      "\tstatic cpumask_t new_cpus;\n",
      "\tstatic nodemask_t new_mems;\n",
      "\tbool cpus_updated, mems_updated;\n",
      "\tbool on_dfl = cgroup_on_dfl(top_cpuset.css.cgroup);\n",
      "\n",
      "\tmutex_lock(&cpuset_mutex);\n",
      "}\n",
      "\n",
      "static ssize_t tstats_write(struct file *file, unsigned int cmd, unsigned long arg)\n",
      "{\n",
      "\tstruct parallel_data *pd = NULL;\n",
      "\n",
      "\tif (cpumask_test_cpu(cpu, rq->rd->span));\n",
      "\t\t\tset_rq_offline(rq);\n",
      "\n",
      "\t\tcpumask_clear_cpu(cpu, tick_broadcast_on))\n",
      "\t\t\tcp\n"
     ]
    }
   ],
   "source": [
    "print generate_text(lm, 20, nletters=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order 10 is pretty much junk. In order 15 things sort-of make sense, but we jump abruptly between the \n",
    "and by order 20 we are doing quite nicely -- but are far from keeping good indentation and brackets. \n",
    "\n",
    "How could we? we do not have the memory, and these things are not modeled at all. While we could quite easily enrich our model to support also keeping track of brackets and indentation (by adding information such as \"have I seen ( but not )\" to the conditioning history), this requires extra work, non-trivial human reasoning, and will make the model significantly more complex. \n",
    "\n",
    "The LSTM, on the other hand, seemed to have just learn it on its own. And that's impressive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
